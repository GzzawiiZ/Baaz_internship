{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X, theta):\n",
    "    return np.dot(X, theta)\n",
    " \n",
    "# function to compute gradient of error function w.r.t. theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def gradient(X, y, theta):\n",
    "    h = hypothesis(X, theta)\n",
    "    grad = np.dot(X.transpose(), (h - y))\n",
    "    return grad\n",
    " \n",
    "# function to compute the error for current values of theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    h = hypothesis(X, theta)\n",
    "    J = np.dot((h - y).transpose(), (h - y))\n",
    "    J /= 2\n",
    "    return J[0]\n",
    " \n",
    "# function to create a list containing mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batches(X, y, batch_size):\n",
    "    mini_batches = []\n",
    "    data = np.hstack((X, y))\n",
    "    np.random.shuffle(data)\n",
    "    n_minibatches = data.shape[0] // batch_size\n",
    "    i = 0\n",
    " \n",
    "    for i in range(n_minibatches + 1):\n",
    "        mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        mini_batches.append((X_mini, Y_mini))\n",
    "    if data.shape[0] % batch_size != 0:\n",
    "        mini_batch = data[i * batch_size:data.shape[0]]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        mini_batches.append((X_mini, Y_mini))\n",
    "    return mini_batches\n",
    " \n",
    "# function to perform mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def gradientDescent(X, y, learning_rate=0.001, batch_size=32):\n",
    "    theta = np.zeros((X.shape[1], 1))\n",
    "    error_list = []\n",
    "    max_iters = 3\n",
    "    for itr in range(max_iters):\n",
    "        mini_batches = create_mini_batches(X, y, batch_size)\n",
    "        for mini_batch in mini_batches:\n",
    "            X_mini, y_mini = mini_batch\n",
    "            theta = theta - learning_rate * gradient(X_mini, y_mini, theta)\n",
    "            error_list.append(cost(X_mini, y_mini, theta))\n",
    " \n",
    "    return theta, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.rand(100,1)\n",
    "Y=(np.random.rand(100,1))*3.76+np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65114907],\n",
       "       [0.95286878],\n",
       "       [0.87587267],\n",
       "       [0.19698928],\n",
       "       [0.60285123],\n",
       "       [0.60234239],\n",
       "       [0.69567889],\n",
       "       [0.96610101],\n",
       "       [0.89702324],\n",
       "       [0.89924631],\n",
       "       [0.29187273],\n",
       "       [0.35249084],\n",
       "       [0.75718523],\n",
       "       [0.75814477],\n",
       "       [0.49433341],\n",
       "       [0.28283963],\n",
       "       [0.31204479],\n",
       "       [0.31581754],\n",
       "       [0.18532762],\n",
       "       [0.11559004],\n",
       "       [0.35826606],\n",
       "       [0.37527664],\n",
       "       [0.7372061 ],\n",
       "       [0.29099494],\n",
       "       [0.02477164],\n",
       "       [0.60697627],\n",
       "       [0.01073419],\n",
       "       [0.91862476],\n",
       "       [0.62437343],\n",
       "       [0.76001704],\n",
       "       [0.88372238],\n",
       "       [0.2813152 ],\n",
       "       [0.74558857],\n",
       "       [0.32248108],\n",
       "       [0.3295585 ],\n",
       "       [0.8175591 ],\n",
       "       [0.4303845 ],\n",
       "       [0.64120997],\n",
       "       [0.56477102],\n",
       "       [0.04375453],\n",
       "       [0.16343467],\n",
       "       [0.63600755],\n",
       "       [0.49122923],\n",
       "       [0.3146616 ],\n",
       "       [0.04077521],\n",
       "       [0.56203041],\n",
       "       [0.58734107],\n",
       "       [0.35713005],\n",
       "       [0.57554244],\n",
       "       [0.95940202],\n",
       "       [0.62078707],\n",
       "       [0.2728236 ],\n",
       "       [0.99887202],\n",
       "       [0.39666776],\n",
       "       [0.96457583],\n",
       "       [0.55289536],\n",
       "       [0.82820128],\n",
       "       [0.08942557],\n",
       "       [0.22218515],\n",
       "       [0.65954233],\n",
       "       [0.60476827],\n",
       "       [0.47473675],\n",
       "       [0.82983156],\n",
       "       [0.75800246],\n",
       "       [0.39761274],\n",
       "       [0.38533024],\n",
       "       [0.32836096],\n",
       "       [0.05716816],\n",
       "       [0.9485335 ],\n",
       "       [0.60215058],\n",
       "       [0.84928005],\n",
       "       [0.28479925],\n",
       "       [0.44138429],\n",
       "       [0.39006378],\n",
       "       [0.82312843],\n",
       "       [0.21059535],\n",
       "       [0.00945949],\n",
       "       [0.59383371],\n",
       "       [0.72228402],\n",
       "       [0.06352258],\n",
       "       [0.75871256],\n",
       "       [0.39684114],\n",
       "       [0.55879491],\n",
       "       [0.75942755],\n",
       "       [0.40832916],\n",
       "       [0.53949597],\n",
       "       [0.03786148],\n",
       "       [0.84198841],\n",
       "       [0.48104355],\n",
       "       [0.20934675],\n",
       "       [0.67977818],\n",
       "       [0.83797274],\n",
       "       [0.30348829],\n",
       "       [0.79980896],\n",
       "       [0.97408312],\n",
       "       [0.84720118],\n",
       "       [0.31256421],\n",
       "       [0.6185632 ],\n",
       "       [0.7467339 ],\n",
       "       [0.28966688]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,error=gradientDescent(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30704555]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "817775b52db1653991b8eead0337b5f576be1e32f04818ee03b008d3f723b26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
